---
layout: about
image: /assets/img/about_me/me_square_427.jpg
description: >
  Description of Andy Keller
hide_description: true
redirect_from:
  - /download/
---


![me](/assets/img/about_me/me_square_427.jpg){: location='left' width="427" height="427" loading="lazy"}


# About Me
{:.lead}

**Find [my full C.V. here](/assets/img/about_me/cv.pdf)**

**Find [my publication list on Google Scholar](https://scholar.google.com/citations?user=Tb86kC0AAAAJ)**


My first name is Thomas, but most people call me by my middle name -- Andy. I'm currently a Research Fellow at the [Kempner Institute at Harvard University](https://kempnerinstitute.harvard.edu), focused on developing deep probabilistic generative models that are meaningfully structured with respect to observed, real-world transformations. Such structure permits both improved generalization in previously unobserved settings and reduced sample complexity on natural tasks, thereby addressing two of the fundamental limitations of modern deep neural networks. The approaches I have taken to develop such structured representation learning algorithms have been directly motivated by observations from neuroscience —- such as topographic organization and cortical traveling waves -- and are further reinforced by ideas from machine learning and cognitive theory, such as equivariance, optimal transport, and intuitive physics. In the long term, the goal of my research is to understand the abstract mechanisms underlying the apparent sample efficiency and generalizability of natural intelligence, and then integrate these into artificially intelligent systems. In the short term, I hope to be able to answer the question of how transformations and invariances are learned and encoded in the brain, what inductive biases lie behind our natural abilities, and to further understand how the two-dimensional structure of the cortical surface shapes how learning proceeds.

My background is in machine learning and computer science, having pursued undergraduate and masters degrees at Caltech and UCSD respectively, then working on deep learning research at Intel Nervana. Most recently, I completed my PhD at the University of Amsterdam under the supervision of Max Welling, where I became fascinated with the brain and how its physical organization might play a role in computation. Simultaneously, I got excited by the question of how abstract computational systems might represent the complex, ever-changing world in structured ways. As a result, my studies naturally gravitated towards the intersection of these two ideas, largely by building new deep neural network models to test long-standing hypotheses from neuroscience relating structure to function. Ultimately, my work at the Kempner Institute is a direct continuation of these ideas, with the ultimate goal of developing the next generation of artificial neural networks to help us understand the brain in new and meaningful ways.


## Education (click <img src="/assets/img/about_me/triangle.jpg" width="20"/> to expand)
<details>
  <summary markdown="span"> **Kempner Research Fellow (Postdoctoral)** *(2023 - Now)* Harvard University, Kempner Institute   </summary>

  In Collaboration With: Talia Konkle, Demba Ba, Cengiz Pehlevan, Kanaka Rajan.
</details>

<details>
  <summary markdown="span"> **Ph.D. Machine Learning** *(2018 - 2023)* University of Amsterdam   </summary>

  Supervisor: Max Welling <br/>
  Thesis: Natural Inductive Biases for Artificial Intelligence
</details>

<details>
  <summary markdown="span"> **M.S. Computer Science** *(2015 - 2017)* University of California San Diego </summary>
Supervisor: Garrison Cottrell<br/>
Thesis: <emph>Comparison and Fine-grained Analysis of Sequence Encoders for Natural Language Processing</emph><br/>
</details>

<details>
  <summary markdown="span"> **B.S. Computer Science w/ Honors** *(2011 - 2015)* California Institute of Technology  </summary>
  Supervisor: Yasser Abu-Mostafa
</details>


## Experience
<details>
  <summary markdown="span">  **Apple Machine Learning Research** (Summer 2022)  </summary>
  <ul>
    <li> Developed ”Homomorphic Self-Supervised Learning”, a framework which subsumes data augmentation in self-supervised learning through structured equivariant representations. </li>
    <li> Published NeurIPS 2022 Self-Supervised Learninng Workshop paper based on work, full AISTATS paper still under review.  </li>
    <li> Additional work from collaboration in submission at ICML 2023 </li>
  </ul>
</details>


<details>
  <summary markdown="span">  **Intel Nervana AI Lab** (2016 - 2018)  </summary>
  <ul>
    <li> Deep Learning Data Scientist (Sept. 2017 - Sept. 2018) </li>
    <li> Algorithms Engineer Intern (June 2016 - June 2017)</li>
  </ul>
</details>

<details>
  <summary markdown="span"> **Data Science for Social Good** (Summer fellow 2015) </summary>
  <ul>
    <li>Project Page: <a href='http://www.dssgfellowship.org/project/improving-long-term-financial-soundness-by-identifying-causes-of-home-abandonment-in-mexico/'>Improving Long-Term Financial Soundness by Identifying Causes of Home Abandonment in Mexico</a></li>
    <li>Paper: <a href="https://www.kdd.org/kdd2016/papers/files/adf0913-ackermannA.pdf">Designing Policy Recommendations to Reduce Home Abandonment in Mexico</a> . KDD 2016</li>
  </ul>
</details>

<details>
  <summary markdown="span"> **Lyve Minds Inc.** (Analytics Engineering Intern Summer 2014) </summary>
  <ul>
    <li>Developed supervised learning algorithm for automatic editing and summarization of user generated handheld video based on predicted level of interest.</li>
  </ul>
</details>

<details>
  <summary markdown="span"> **California Institute of Technology** (Undergraduate Researcher 2012) </summary>

  <ul>
    <li>Paper: <a href="https://arxiv.org/abs/1308.1483">Experimental Realization of a Nonlinear Acoustic Lens with a Tunable Focus</a></li>
    <li>Gathered and analyzed waveforms from an acoustinc lens to determine optimal characteristics of interface materials.</li>
  </ul>
</details>

## Teaching
### Master's Thesis Supervision
- **Qinghe Gao**: Modeling the Observed Domain-Specificity in the Visual Cortex using Topographic Variational Autoencoders (in submission)
- **Samarth Bhargav**: [Geometric Priors for Disentangling Representations](http://scriptiesonline.uba.uva.nl/document/676481)
- **Noah van Grinsven**:[Spatio-Temporal Forecasting On Graphs With Incomplete Data](https://scripties.uba.uva.nl/search?id=719556)
- **Fiorella Wever**: [As easy as APC: Leveraging self-supervised learning in the context of time series classification with varying levels of sparsity and severe class imbalance](https://arxiv.org/abs/2106.15577)

### As Teaching Assistant
- Leren (Bachelor's Machine Learning)
- Machine Learning 2 (Second Year Master's)
- [Data Visualization](https://mas-dse.github.io/DSE241/exercises/) (D3.js) 

## Personal
Privately, I enjoy cooking ([@TheOtherThomasKeller](https://www.instagram.com/theotherthomaskeller/)), running, and playing with my gymnastics rings. I was also an organizing member of the [Inclusive AI](https://uva-iai.github.io/) group at the UvA whose goal is to reduce harmful bias (both algorithmic and human) in the field of machine learning. Please feel free to email me if you have any questions!

## Twitter

<div style="width: 100%; overflow: hidden;">
     <div style="margin-left: 50px; width: 350px; height: 454px; float: left;">  <a class="twitter-timeline" href="https://twitter.com/t_andy_keller?ref_src=twsrc%5Etfw">Tweets by t_andy_keller</a><script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
</div>

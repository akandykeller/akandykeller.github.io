---
layout: post
title: Predictive Coding with Topographic VAEs
<!-- image: /assets/img/research/pctvae/pctvae_vs_tvae.png -->
sitemap: false
comments: true
---
<!-- ![Full-width image](/assets/img/overview_long.png){:.lead width="800" height="100" loading="lazy"} -->
![PCTVAE Overview](/assets/img/research/pctvae/pctvae_vs_tvae.png){:.lead width="3335" height="1325" loading="lazy"}
We introduce a modification of the Topographic VAE, allowing it to be used in an online manner as a _predictive_ model of the future. We observe that the Predictive Coding TVAE (PCTVAE) is able to learn more coherent sequence transformations (left) when compared with the original Topographic VAE (right). 
{:.figcaption}



Predictive coding is a model of visual processing which suggests that the brain is a generative model of input, with prediction error serving as a signal for both learning and attention. In this work, we show how the equivariant capsules learned by a Topographic Variational Autoencoder can be extended to fit within the predictive coding framework by treating the slow rolling of capsule activations as the forward prediction operator. We demonstrate quantitatively that such an extension leads to improved sequence modeling compared with both topographic and non-topographic baselines, and that the resulting forward predictions are qualitatively more coherent with the provided partial input transformations. 
{:.note title="Abstract"}
**T. Anderson Keller**, [Max Welling](https://staff.fnwi.uva.nl/m.welling/)
{:.note title="Authors"}
*Paper*: <https://openreview.net/pdf?id=WvUOFEESncx>  \\
*Oral presentation at:* [ICCV 2021 VIPriors Workshop](https://vipriors.github.io/)
{:.note title="Full Paper"}
[Github.com/AKAndykeller/PCTVAE](https://github.com/akandykeller/PCTVAE)
{:.note title="Code"}
 


<!-- {:.lead} -->


 
- Table of Contents
{:toc}
